# -*- coding: utf-8 -*-
"""Toon Image Creator IVP SEM 5 J001 & J064.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hrI9-hOQw2yo48wAaXvsnYI22PMjbZNZ

***Name of the Project -: Toon Image Creator***

**Programming language used-: Python**

**Platform used-: Google Colab**

**Group Member details -: **

1.   Ekansh Agarwal (J001)
2.   Aakarsh Kumar (J064)

**Subject -: IVP (Image and Video Processing) **

***Semester - : 5 ***

***Course -: MBA(tech) EXTC***

***Ouline of the project -:  This Project is the implementation of  Progressive resizing and generator loss which takes this idea of gradually increasing the image size, In this project the image size were gradually increased and learning rates were adjusted. For performing this study we have used the concepts of Upscaling and interpolation

Library Used- :  

1.   Numpy
2.   Fast Ai
3.   PIL Image
4.   Urlib
5.   Torchvision
"""

# Importing Libraries
import fastai
from fastai.vision import *
from fastai.utils.mem import *
from fastai.vision import open_image, load_learner, image, torch
import numpy as np
import urllib.request
import PIL.Image
from io import BytesIO
import torchvision.transforms as T
from PIL import Image
import requests
from io import BytesIO
import fastai
from fastai.vision import *
from fastai.utils.mem import *
from fastai.vision import open_image, load_learner, image, torch
import numpy as np
import urllib.request
import PIL.Image
from PIL import Image
from io import BytesIO
import torchvision.transforms as T

# Defining Classes for altering the features of the potrait (original image)
# These individuals classes are use to collect data such as RGB data , margin , outline data
class FeatureLoss(nn.Module):
    def __init__(self, m_feat, layer_ids, layer_wgts):
        super().__init__()
        self.m_feat = m_feat
        self.loss_features = [self.m_feat[i] for i in layer_ids]
        self.hooks = hook_outputs(self.loss_features, detach=False)
        self.wgts = layer_wgts
        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))
              ] + [f'gram_{i}' for i in range(len(layer_ids))]

    def make_features(self, x, clone=False):
        self.m_feat(x)
        return [(o.clone() if clone else o) for o in self.hooks.stored]

    def forward(self, input, target):
        out_feat = self.make_features(target, clone=True)
        in_feat = self.make_features(input)
        self.feat_losses = [base_loss(input,target)]
        self.feat_losses += [base_loss(f_in, f_out)*w
                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]
        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3
                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]
        self.metrics = dict(zip(self.metric_names, self.feat_losses))
        return sum(self.feat_losses)

    def __del__(self): self.hooks.remove()

def add_margin(pil_img, top, right, bottom, left, color):
    width, height = pil_img.size
    new_width = width + right + left
    new_height = height + top + bottom
    result = Image.new(pil_img.mode, (new_width, new_height), color)
    result.paste(pil_img, (left, top))
    return result

"""## **In this section the image is extracted from url and is interpolated**"""

url = "https://mediamass.net/jdd/public/documents/celebrities/3946.jpg" #@param {type:"string"}

response = requests.get(url)
img = PIL.Image.open(BytesIO(response.content)).convert("RGB")
im_new = add_margin(img, 150, 150, 150, 150, (255, 255, 255))
im_new.save("test.jpg", quality=95)
img = open_image("test.jpg")
show_image(img, figsize=(10,10), interpolation='nearest');

p,img_hr,b = learn.predict(img)
x = np.minimum(np.maximum(image2np(img_hr.data*255), 0), 255).astype(np.uint8)
PIL.Image.fromarray(x).save("tes.jpg",quality=95)
img = open_image("tes.jpg")

"""***reulted image***"""

p,img_hr,b = learn_c.predict(img)
show_image(img_hr, figsize=(9,9), interpolation='nearest');

"""References

1.  [ Perceptual Losses for Real-Time Style Transfer
and Super-Resolution](https://https://arxiv.org/pdf/1603.08155.pdf)
2.   [Enhanced Deep Residual Networks for Single Image Super-Resolution](https://arxiv.org/pdf/1707.02921.pdf)



"""